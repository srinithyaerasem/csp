{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2d3fca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from textwrap import wrap\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "369f9539",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/Nikhil/Desktop/pest_split_dataset/classes.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC:/Users/Nikhil/Desktop/pest_split_dataset/classes.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m label \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m name \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py:308\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    303\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    304\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    305\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    306\u001b[0m     )\n\u001b[1;32m--> 308\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/Nikhil/Desktop/pest_split_dataset/classes.txt'"
     ]
    }
   ],
   "source": [
    "f = open('C:/Users/Nikhil/Desktop/pest_split_dataset/classes.txt')\n",
    "label = []\n",
    "name = []\n",
    "for line in f.readlines():\n",
    "    label.append(int(line.split()[0]))\n",
    "    name.append(' '.join(line.split()[1:]))\n",
    "classes = pd.DataFrame([label, name]).T\n",
    "classes.columns = ['label','name']\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb8b0aa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('C:/Users/Nikhil/Desktop/pest_split_dataset/train.txt',sep=' ',header=None, engine='python')\n",
    "train_df.columns = ['image_path','label']\n",
    "\n",
    "test_df = pd.read_csv('C:/Users/Nikhil/Desktop/pest_split_dataset/test.txt',sep=' ',header=None, engine='python')\n",
    "test_df.columns = ['image_path','label']\n",
    "\n",
    "val_df = pd.read_csv('C:/Users/Nikhil/Desktop/pest_split_dataset/val.txt',sep=' ',header=None, engine='python')\n",
    "val_df.columns = ['image_path','label']\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b84dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'C:/Users/Nikhil/Desktop/pest_split_dataset/train'\n",
    "TEST_DIR = 'C:/Users/Nikhil/Desktop/pest_split_dataset/test'\n",
    "VAL_DIR = 'C:/Users/Nikhil/Desktop/pest_split_dataset/val'\n",
    "LR = 2e-5\n",
    "BATCH_SIZE = 8\n",
    "EPOCH = 2\n",
    "\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bea4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(10,11,figsize=(30,30))\n",
    "images = []\n",
    "for i in classes.label:\n",
    "    random_img = random.choice(train_df[train_df.label==i-1].image_path.values)\n",
    "    label = classes.name[i-1]\n",
    "    img = plt.imread(os.path.join(TRAIN_DIR,str(i-1),random_img))\n",
    "    images.append(img)\n",
    "\n",
    "[ax.imshow(image) for image,ax in zip(images,axs.ravel())]\n",
    "[ax.set_title(\"\\n\".join(wrap(label,20))) for label,ax in zip(list(classes.name),axs.ravel())]\n",
    "[ax.set_axis_off() for ax in axs.ravel()]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1938269f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InsectModel(nn.Module):\n",
    "    def __init__(self,num_classes):\n",
    "        super(InsectModel, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.model = timm.create_model('vit_base_patch16_224',pretrained=True,num_classes=num_classes)\n",
    "    def forward(self, image):\n",
    "        return self.model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc71c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_transform():\n",
    "    return A.Compose([\n",
    "        A.HorizontalFlip(),\n",
    "        A.RandomRotate90(),\n",
    "        A.RandomBrightnessContrast(),\n",
    "        A.Resize(224, 224),\n",
    "        ToTensorV2()])\n",
    "\n",
    "def valid_transform():\n",
    "    return A.Compose([\n",
    "        A.Resize(224,224),\n",
    "        ToTensorV2()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d9aa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16bb84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InsectDataset(Dataset):\n",
    "    def __init__(self, image, image_dir, transforms=None):\n",
    "        self.image_info = image\n",
    "        self.transforms = transforms\n",
    "        self.imgdir = image_dir\n",
    "    def __len__(self):\n",
    "        return self.image_info.shape[0]\n",
    "    def __getitem__(self, index):\n",
    "        image_info = self.image_info[index]\n",
    "        try:\n",
    "            image = cv2.imread(os.path.join(self.imgdir, str(image_info[1]), image_info[0]), cv2.IMREAD_COLOR)\n",
    "            if image is None:\n",
    "                raise ValueError(f\"Unable to read image at index {index}\")\n",
    "\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "            image /= 255.\n",
    "\n",
    "            if self.transforms is not None:\n",
    "                image = self.transforms(image=image)['image']\n",
    "\n",
    "            label = image_info[1]\n",
    "\n",
    "            image = torch.as_tensor(image, dtype=torch.float32)\n",
    "            label = torch.as_tensor(label, dtype=torch.long)\n",
    "\n",
    "            return image, label\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image at index {index}: {str(e)}\")\n",
    "        # You might want to handle the error by returning default placeholders or skipping the image\n",
    "        # Example:\n",
    "        # image = np.zeros((width, height, channels), dtype=np.float32)  # Set a placeholder image\n",
    "        # label = -1  # Set a placeholder label\n",
    "        # return torch.tensor(image), torch.tensor(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bb9383",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = InsectDataset(image=train_df.values, \n",
    "                              image_dir=TRAIN_DIR, \n",
    "                              transforms=train_transform())\n",
    "train_data_loader = DataLoader(train_dataset,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True,\n",
    "                              num_workers=0)\n",
    "val_dataset = InsectDataset(image=val_df.values,\n",
    "                            image_dir=VAL_DIR,\n",
    "                            transforms=valid_transform())\n",
    "val_data_loader = DataLoader(val_dataset,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             shuffle=True,\n",
    "                             num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330d94a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.loss = 0\n",
    "        self.correct = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, loss,correct, n=1):\n",
    "        self.loss = loss\n",
    "        self.correct += correct\n",
    "        self.sum += loss * n\n",
    "        self.count += n\n",
    "        \n",
    "        self.avg = self.sum / self.count\n",
    "        self.acc = self.correct / self.count\n",
    "        \n",
    "class Accuracy(object):\n",
    "    def __init__(self):\n",
    "        self.reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd954216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(data_loader, model, criterion, device, optimizer, epoch):\n",
    "    model.train()\n",
    "    criterion.train()\n",
    "    \n",
    "    summary = AverageMeter()\n",
    "    tk0 = tqdm(data_loader, total=len(data_loader))\n",
    "    for step, (images, labels) in enumerate(tk0):\n",
    "        images = images.to(device, non_blocking = True).float()\n",
    "        labels = labels.to(device, non_blocking = True).long()\n",
    "    \n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        preds = output.softmax(1).argmax(1)\n",
    "        correct = (preds == labels).sum().item()\n",
    "        \n",
    "        summary.update(loss.item(),correct, BATCH_SIZE)\n",
    "        tk0.set_postfix(loss=summary.avg, acc=summary.acc, epoch=epoch+1)\n",
    "    return summary\n",
    "\n",
    "def eval_fn(data_loader, model, criterion, device, epoch):\n",
    "    model.eval()\n",
    "    criterion.eval()\n",
    "    \n",
    "    summary = AverageMeter()\n",
    "    tk0 = tqdm(data_loader, total=len(data_loader))\n",
    "    with torch.no_grad():\n",
    "        for step, (images, labels) in enumerate(tk0):\n",
    "            images = images.to(device, non_blocking = True).float()\n",
    "            labels = labels.to(device, non_blocking = True).long()\n",
    "            \n",
    "            output = model(images)\n",
    "            loss = criterion(output, labels)\n",
    "            \n",
    "            preds = output.softmax(1).argmax(1)\n",
    "            correct = (preds == labels).sum().item()\n",
    "            \n",
    "            summary.update(loss.item(), correct, BATCH_SIZE)\n",
    "            tk0.set_postfix(loss=summary.avg, acc=summary.acc, epoch=epoch+1)\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f477ddba",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['WANDB_CONSOLE'] = 'off'\n",
    "\n",
    "def run():\n",
    "    model = InsectModel(num_classes=40)\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    criterion = criterion.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "    best_loss = 10**5\n",
    "    for epoch in range(0, EPOCH):\n",
    "        train_loss = train_fn(train_data_loader, model, criterion, device, optimizer, epoch)\n",
    "        val_loss = eval_fn(val_data_loader, model, criterion, device, epoch)\n",
    "        if val_loss.avg < best_loss:\n",
    "            best_loss = val_loss.avg\n",
    "            torch.save(model.state_dict(), f'vit_best.pth')\n",
    "        print(f'Epoch {epoch+1+0:03}: | Train Loss: {train_loss.avg:.5f} | Val Loss: {val_loss.avg:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed76c569",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f940b7",
   "metadata": {},
   "source": [
    "### Accuracy : 99.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efae2c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InsectModel(num_classes=40)\n",
    "model.load_state_dict(torch.load(\"./vit_best.pth\"))\n",
    "images, labels = next(iter(val_data_loader))\n",
    "preds = model(images).softmax(1).argmax(1)\n",
    "\n",
    "fig, axs = plt.subplots(2,4,figsize=(13,8))\n",
    "[ax.imshow(image.permute((1,2,0))) for image,ax in zip(images,axs.ravel())]\n",
    "[ax.set_title(\"\\n\".join(wrap(f'Accutual: {classes.name[label.item()]} Predicted: {classes.name[pred.item()]}',30)),color = 'g' if label.item()==pred.item() else 'r') for label,pred,ax in zip(labels,preds,axs.ravel())]\n",
    "[ax.set_axis_off() for ax in axs.ravel()]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c01adb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2,1,1)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05b0908",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
